{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60478de-1215-441c-af9e-ef3c6cbbb305",
   "metadata": {},
   "source": [
    "<h1>Momentum with Different Polynomials</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753e441-6eb0-4c73-8eb3-0566be61760a",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Saddle\">Saddle Points</a></li>\n",
    "    <li><a href=\"#Minima\">Local Minima</a></li>\n",
    "    <li><a href=\"#Noise\"> Noise </a></li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dab32d-9117-49e6-85e4-d08486cf3d8b",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776077c4-7f1d-4c28-944f-ba7f9f652f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries that will be used for this lab.\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad539ef-9cf2-42de-877c-7d644cb1d959",
   "metadata": {},
   "source": [
    "This function will plot a cubic function and the parameter values obtained via Gradient Descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044ea32-8af6-481e-a143-eca6a7e39ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cubic\n",
    "\n",
    "def plot_cubic(w, optimizer):\n",
    "    LOSS = []\n",
    "    # parameter values \n",
    "    W = torch.arange(-4, 4, 0.1)\n",
    "    # plot the loss fuction \n",
    "    for w.state_dict()['linear.weight'][0] in W:\n",
    "        LOSS.append(cubic(w(torch.tensor([[1.0]]))).item())\n",
    "    w.state_dict()['linear.weight'][0] = 4.0\n",
    "    n_epochs = 10\n",
    "    parameter = []\n",
    "    loss_list = []\n",
    "\n",
    "    # n_epochs\n",
    "    # Use PyTorch custom module to implement a ploynomial function\n",
    "    for n in range(n_epochs):\n",
    "        optimizer.zero_grad() \n",
    "        loss = cubic(w(torch.tensor([[1.0]])))\n",
    "        loss_list.append(loss)\n",
    "        parameter.append(w.state_dict()['linear.weight'][0].detach().data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    plt.plot(parameter, [loss.detach().numpy().flatten()  for loss in loss_list], 'ro', label='parameter values')\n",
    "\n",
    "    plt.plot(W.numpy(), LOSS, label='objective function')\n",
    "    plt.xlabel('w')\n",
    "    plt.ylabel('l(w)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a633a3-5f5d-4683-b54a-9b5444b90c18",
   "metadata": {},
   "source": [
    "This function will plot a 4th order function and the parameter values obtained via Gradient Descent. You can also add Gaussian noise with a standard deviation determined by the parameter <code>std</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e14ccc-3de8-44d4-befd-c474213fa488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fourth order function and the parameter values\n",
    "\n",
    "def plot_fourth_order(w, optimizer, std=0, color='r', paramlabel='parameter values', objfun=True):\n",
    "    W = torch.arange(-4, 6, 0.1)\n",
    "    LOSS = []\n",
    "    for w.state_dict()['linear.weight'][0] in W:\n",
    "        LOSS.append(fourth_order(w(torch.tensor([[1.0]]))).item())\n",
    "    w.state_dict()['linear.weight'][0] = 6\n",
    "    n_epochs = 100\n",
    "    parameter = []\n",
    "    loss_list = []\n",
    "\n",
    "    #n_epochs\n",
    "    for n in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = fourth_order(w(torch.tensor([[1.0]]))) + std * torch.randn(1, 1)\n",
    "        loss_list.append(loss)\n",
    "        parameter.append(w.state_dict()['linear.weight'][0].detach().data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Plotting\n",
    "    if objfun:\n",
    "        plt.plot(W.numpy(), LOSS, label='objective function')\n",
    "    \n",
    "    plt.plot(parameter, [loss.detach().numpy().flatten()  for loss in loss_list], 'ro', label='paramlabel')\n",
    "    plt.xlabel('w')\n",
    "    plt.ylabel('l(w)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d13753-47f6-4871-ba9d-d759afe4176c",
   "metadata": {},
   "source": [
    "This is a custom module. It will behave like a single parameter value. We do it this way so we can use PyTorch's build-in optimizers .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962a3fd-099b-48d4-b1ee-05333372dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear model\n",
    "\n",
    "class one_param(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_param, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size, bias=False)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f8769b-afb4-4daf-ac20-bccd0df9a7fb",
   "metadata": {},
   "source": [
    "We create an object <code>w</code>, when we call the object with an input of one, it will behave like an individual parameter value. i.e <code>w(1)</code> is analogous to $w$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0734b83-8a1d-431a-8a9c-3598eb50b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one_param object\n",
    "\n",
    "w = one_param(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9f74c-df92-4321-8527-90de13cc2141",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865bb24-d833-4bcc-a3b1-50a7a02301ec",
   "metadata": {},
   "source": [
    "<a name=\"Saddle\"><h2 id=\"Saddle\">Saddle Points</h2></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36b074-c7b3-405f-9b70-c264843c47d2",
   "metadata": {},
   "source": [
    "Let's create a cubic function with Saddle points \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cd2a4-904f-44f8-8d11-7d49fa1770af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to output a cubic \n",
    "\n",
    "def cubic(yhat):\n",
    "    out = yhat ** 3\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091b2a5-f78b-4ebb-a6de-a9c4cf8343ff",
   "metadata": {},
   "source": [
    "We create an optimizer with no momentum term \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0517eda-e731-4cd1-8988-c71e838d72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a optimizer without momentum\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.01, momentum=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8a741-3fbb-4f51-9848-9e60d99893c5",
   "metadata": {},
   "source": [
    "We run several iterations of stochastic gradient descent and plot the results. We see the parameter values get stuck in the saddle point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73641c70-72f4-4a06-8dc0-bebbcbfdce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "\n",
    "plot_cubic(w, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a4eba-46a0-4ecc-89a1-f072580d6f67",
   "metadata": {},
   "source": [
    "we create an optimizer with momentum term of 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adc334-0575-445f-88fe-8a536d4d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a optimizer with momentum\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48048a0b-a002-4c65-9f27-3f8f72054f37",
   "metadata": {},
   "source": [
    "We run several iterations of stochastic gradient descent with momentum and plot the results. We see the parameter values do not get stuck in the saddle point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac6be4-f0c2-4e27-9b4a-e57b7cbda25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "\n",
    "plot_cubic(w, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21dfa5a-21e1-4a86-8cbf-2b3a0e7ad6c7",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6c2b9-d4e9-4c64-bb44-acc34092e4c5",
   "metadata": {},
   "source": [
    "<a name=\"Minima\"><h2 id=\"Minima\">Local Minima</h2></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8724f-4b50-4867-8439-5e29b944e06b",
   "metadata": {},
   "source": [
    "In this section, we will create a fourth order polynomial with a local minimum at <i>4</i> and a global minimum a <i>-2</i>. We will then see how the momentum parameter affects convergence to a global minimum. The fourth order polynomial is given by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0d422-3020-47f3-bfcb-087d0fde7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the fourth order polynomial \n",
    "\n",
    "def fourth_order(yhat): \n",
    "    out = torch.mean(2 * (yhat ** 4) - 9 * (yhat ** 3) - 21 * (yhat ** 2) + 88 * yhat + 48)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1effd17-7582-40dc-aade-ff99325d6c93",
   "metadata": {},
   "source": [
    "We create an optimizer with no momentum term. We run several iterations of stochastic gradient descent and plot the results. We see the parameter values get stuck in the local minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592aedf-322d-4fbe-acc9-ad7c37bd0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction without momentum\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.001)\n",
    "plot_fourth_order(w, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80137e93-3f83-49ee-a62a-9e89cf68e4f6",
   "metadata": {},
   "source": [
    "We create an optimizer with a  momentum term of 0.9. We run several iterations of stochastic gradient descent and plot the results. We see the parameter values reach a global minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c08d6-0556-4e40-80eb-26a1c3860974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction with momentum\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.001, momentum=0.9)\n",
    "plot_fourth_order(w, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e6ba5-a679-4bca-b924-25a454b5ca34",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24def79-656d-46d1-90ba-a284c2a587f7",
   "metadata": {},
   "source": [
    "<a name=\"Noise\"><h2 id=\"Noise\">Noise</h2></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d268ed2-da3d-4401-8742-160700cb87f2",
   "metadata": {},
   "source": [
    "In this section, we will create a fourth order polynomial with a local minimum at 4 and a global minimum a -2, but we will add noise to the function when the Gradient is calculated. We will then see how the momentum parameter affects convergence to a global minimum. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc409e-ba2d-4efc-9bf8-f38d98aadade",
   "metadata": {},
   "source": [
    "with no momentum, we get stuck in a local minimum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585174f-9e35-4177-9d5f-1f3e97164e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction without momentum when there is noise\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.001)\n",
    "plot_fourth_order(w, optimizer, std=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b0fdf-d110-4500-9e3d-c7a3feb55c24",
   "metadata": {},
   "source": [
    "with  momentum, we get to the global  minimum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bd1f8-1fcd-43b5-86d4-64e6e0c49225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction with momentum when there is noise\n",
    "\n",
    "optimizer = torch.optim.SGD(w.parameters(), lr=0.001,momentum=0.9)\n",
    "plot_fourth_order(w, optimizer, std=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c96ab-8c39-4ce8-9fca-d6b77416ec23",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learning)",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "d143ba85f057f77848ceacfd994791828fd04aed3c8c5ce944bf9a8423695be1"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
